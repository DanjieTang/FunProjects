{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "564a3be6",
      "metadata": {
        "id": "564a3be6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as opt\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fbf70fe",
      "metadata": {
        "id": "5fbf70fe"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, image_width: int, image_height: int, num_of_layers: int, input_size: int, drop_out_rate: float):\n",
        "        super().__init__()\n",
        "        self.num_pixel = image_width * image_height\n",
        "        self.num_of_layers = num_of_layers\n",
        "        self.input_size = input_size\n",
        "        self.drop_out_rate = drop_out_rate\n",
        "        self.image_width = image_width\n",
        "        self.image_height = image_height\n",
        "\n",
        "        #This is how many neurons I am going to increase/decrease between each layer\n",
        "        increase_decrease_size = int((self.num_pixel - self.input_size) / self.num_of_layers)\n",
        "\n",
        "        self.generator = nn.Sequential(nn.Linear(input_size, input_size+increase_decrease_size),\n",
        "                                       nn.LeakyReLU(),\n",
        "                                       nn.Dropout(self.drop_out_rate),\n",
        "                                       nn.Linear(input_size+increase_decrease_size, input_size+increase_decrease_size*2),\n",
        "                                       nn.LeakyReLU(),\n",
        "                                       nn.Dropout(self.drop_out_rate),\n",
        "                                       nn.Linear(input_size+increase_decrease_size*2, input_size+increase_decrease_size*3),\n",
        "                                       nn.LeakyReLU(),\n",
        "                                       nn.Dropout(self.drop_out_rate),\n",
        "                                       nn.Linear(input_size+increase_decrease_size*3, input_size+increase_decrease_size*4),\n",
        "                                       nn.LeakyReLU(),\n",
        "                                       nn.Dropout(self.drop_out_rate),\n",
        "                                       nn.Linear(input_size+increase_decrease_size*4, input_size+increase_decrease_size*5),\n",
        "                                       nn.LeakyReLU(),\n",
        "                                       nn.Dropout(self.drop_out_rate),\n",
        "                                       nn.Linear(input_size+increase_decrease_size*5, self.num_pixel),\n",
        "                                       nn.Tanh())\n",
        "\n",
        "    def forward(self, tensor):\n",
        "        tensor = self.generator(tensor)\n",
        "        images = tensor.view(-1, 1, self.image_width, self.image_height)\n",
        "        return images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec5ea5a3",
      "metadata": {
        "id": "ec5ea5a3"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, image_width: int, image_height: int, num_of_layers: int, input_size: int, drop_out_rate: float):\n",
        "        super().__init__()\n",
        "        self.num_pixel = image_width * image_height\n",
        "        self.num_of_layers = num_of_layers\n",
        "        self.input_size = input_size\n",
        "        self.drop_out_rate = drop_out_rate\n",
        "\n",
        "        #This is how many neurons I am going to increase/decrease between each layer\n",
        "        increase_decrease_size = int((self.num_pixel - self.input_size) / self.num_of_layers)\n",
        "\n",
        "        self.discriminator = nn.Sequential(nn.Linear(self.num_pixel, input_size+increase_decrease_size*5),\n",
        "                                           nn.LeakyReLU(),\n",
        "                                           nn.Dropout(self.drop_out_rate),\n",
        "                                           nn.Linear(input_size+increase_decrease_size*5, input_size+increase_decrease_size*4),\n",
        "                                           nn.LeakyReLU(),\n",
        "                                           nn.Dropout(self.drop_out_rate),\n",
        "                                           nn.Linear(input_size+increase_decrease_size*4, input_size+increase_decrease_size*3),\n",
        "                                           nn.LeakyReLU(),\n",
        "                                           nn.Dropout(self.drop_out_rate),\n",
        "                                           nn.Linear(input_size+increase_decrease_size*3, input_size+increase_decrease_size*2),\n",
        "                                           nn.LeakyReLU(),\n",
        "                                           nn.Dropout(self.drop_out_rate),\n",
        "                                           nn.Linear(input_size+increase_decrease_size*2, input_size+increase_decrease_size),\n",
        "                                           nn.LeakyReLU(),\n",
        "                                           nn.Dropout(self.drop_out_rate),\n",
        "                                           nn.Linear(input_size+increase_decrease_size, 11))\n",
        "\n",
        "    def forward(self, images):\n",
        "        tensor = images.view(-1, self.num_pixel)\n",
        "        tensor = self.discriminator(tensor)\n",
        "        return tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48907971",
      "metadata": {
        "id": "48907971"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "batch_size = 256\n",
        "epochs = 20\n",
        "lr = 2e-4\n",
        "weight_decay = 1e-3\n",
        "drop_out_rate = 0.3\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5db81ff",
      "metadata": {
        "id": "d5db81ff"
      },
      "outputs": [],
      "source": [
        "# Prepare the dataset\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# Download and load the training data\n",
        "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc0763bb",
      "metadata": {
        "id": "fc0763bb"
      },
      "outputs": [],
      "source": [
        "#Instantiate the model\n",
        "generator = Generator(image_width=28, image_height=28, num_of_layers=6, input_size=20, drop_out_rate=drop_out_rate).to(device)\n",
        "discriminator = Discriminator(image_width=28, image_height=28, num_of_layers=6, input_size=20, drop_out_rate=drop_out_rate).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52203ace",
      "metadata": {
        "id": "52203ace"
      },
      "outputs": [],
      "source": [
        "class ExponentialLRWithMin:\n",
        "    def __init__(self, optimizer, gamma, min_lr):\n",
        "        self.optimizer = optimizer\n",
        "        self.gamma = gamma\n",
        "        self.min_lr = min_lr\n",
        "\n",
        "    def step(self):\n",
        "        for param_group in self.optimizer.param_groups:\n",
        "            param_group['lr'] = max(param_group['lr'] * self.gamma, self.min_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c898189",
      "metadata": {
        "id": "4c898189"
      },
      "outputs": [],
      "source": [
        "optimizer_G = opt.Adam(generator.parameters(), lr = lr, weight_decay = weight_decay)\n",
        "optimizer_D = opt.Adam(discriminator.parameters(), lr = lr, weight_decay = weight_decay)\n",
        "\n",
        "scheduler_generator = ExponentialLRWithMin(optimizer_G, gamma=0.95, min_lr=2e-5)\n",
        "scheduler_discriminator = ExponentialLRWithMin(optimizer_D, gamma=0.95, min_lr=2e-5)\n",
        "\n",
        "auxiliary_criterion = nn.MSELoss()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define the image augmentation\n",
        "transform = transforms.Compose([transforms.ToPILImage(),\n",
        "                                transforms.RandomAffine(0, translate = (0.2, 0.2)),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,), (0.5,))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c593b2b",
      "metadata": {
        "id": "8c593b2b"
      },
      "outputs": [],
      "source": [
        "def input_creator(labels):\n",
        "    list_of_input = []\n",
        "    for i in range(labels.numel()):\n",
        "        noise = torch.randn(10)\n",
        "        label = torch.zeros(10)\n",
        "        label[labels[i]] = 1\n",
        "\n",
        "        input = torch.concatenate((noise, label), 0)\n",
        "        list_of_input.append(input)\n",
        "\n",
        "    list_of_input = torch.stack(list_of_input)\n",
        "    list_of_input = list_of_input.view(-1, 20)\n",
        "    list_of_input = list_of_input.to(device)\n",
        "    return list_of_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d89caa2b",
      "metadata": {
        "id": "d89caa2b"
      },
      "outputs": [],
      "source": [
        "def find_label(labels):\n",
        "    list_of_input = []\n",
        "    for i in range(labels.numel()):\n",
        "        label = torch.zeros(11)\n",
        "        label[labels[i]] = 1\n",
        "\n",
        "        list_of_input.append(label)\n",
        "\n",
        "    list_of_input = torch.stack(list_of_input)\n",
        "    list_of_input = list_of_input.to(device)\n",
        "    return list_of_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7d35065",
      "metadata": {
        "id": "a7d35065"
      },
      "outputs": [],
      "source": [
        "def create_fake_label(output):\n",
        "    label = torch.zeros_like(output).to(device)\n",
        "    label[:,10] = 1\n",
        "    return label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94ccd432",
      "metadata": {
        "id": "94ccd432"
      },
      "outputs": [],
      "source": [
        "def augment_image(image):\n",
        "    # To the best of my knowledge, transform doesn't support a batch of images\n",
        "    list_of_tensors = []\n",
        "    for i in range(image.shape[0]):\n",
        "        tensor = transform(image[i])\n",
        "        list_of_tensors.append(tensor)\n",
        "\n",
        "    tensor = torch.stack(list_of_tensors)\n",
        "    tensor = tensor.to(device)\n",
        "    return tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "511bf96f",
      "metadata": {
        "id": "511bf96f"
      },
      "outputs": [],
      "source": [
        "def small_noise_for_latent_space(input_tensors):\n",
        "    noise_tensor = torch.randn_like(input_tensors) * 0.07\n",
        "    noise_tensor[:, 10:] = 0\n",
        "    return noise_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f78259cb",
      "metadata": {
        "id": "f78259cb"
      },
      "outputs": [],
      "source": [
        "#Training\n",
        "\n",
        "epoch_discriminator_loss = 0\n",
        "epoch_generator_loss = 0\n",
        "\n",
        "train_discriminator_num = 1\n",
        "train_generator_num = 1\n",
        "\n",
        "visualization_labels = torch.tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]).to(device)\n",
        "\n",
        "while(1):\n",
        "    for images, labels in trainloader:\n",
        "        # Create the image augmentation of real images\n",
        "        augmented_real_images = augment_image(images)\n",
        "\n",
        "        images = images.to(device)\n",
        "\n",
        "        # Train discriminator\n",
        "        # if((epoch_discriminator_loss - epoch_generator_loss)>3):\n",
        "        #     train_discriminator_num = 2\n",
        "        # else:\n",
        "        #     train_discriminator_num = 1\n",
        "\n",
        "        for _ in range(train_discriminator_num):\n",
        "            #This is the real image\n",
        "            output_real = discriminator(images)\n",
        "            label = find_label(labels)\n",
        "            loss_discriminator_real = criterion(output_real, label)\n",
        "\n",
        "            # This is fake image\n",
        "            input_tensors = input_creator(labels)\n",
        "            images_generated = generator(input_tensors)\n",
        "            output_fake = discriminator(images_generated)\n",
        "            label = create_fake_label(output_fake)\n",
        "            loss_discriminator_fake = criterion(output_fake, label)\n",
        "\n",
        "            # Create the image augmentation of fake images\n",
        "            augmented_fake_images = augment_image(images_generated)\n",
        "\n",
        "            # This is the auxiliary loss\n",
        "            output_real_augmented = discriminator(augmented_real_images)\n",
        "            loss_real_augmented = auxiliary_criterion(output_real_augmented, output_real)\n",
        "\n",
        "            output_fake_augmented = discriminator(augmented_fake_images)\n",
        "            loss_fake_augmented = auxiliary_criterion(output_fake_augmented, output_fake)\n",
        "\n",
        "            # input_tensors = input_tensors + small_noise_for_latent_space(input_tensors)\n",
        "            # images_generated = generator(input_tensors)\n",
        "            # output_fake_zcr = discriminator(images_generated)\n",
        "            # loss_fake_zcr = auxiliary_criterion(output_fake_zcr, output_fake)\n",
        "\n",
        "            optimizer_D.zero_grad()\n",
        "            loss_discriminator = loss_discriminator_real + 0.2 * loss_discriminator_fake + 0.2 * loss_real_augmented + 0.2 * loss_fake_augmented# + 0.2 * loss_fake_zcr\n",
        "            if(labels.numel() != batch_size):\n",
        "                epoch_discriminator_loss = loss_discriminator.item()\n",
        "                print(\"Discriminator loss\", loss_discriminator.item())\n",
        "            loss_discriminator.backward()\n",
        "            optimizer_D.step()\n",
        "\n",
        "        # Train generator\n",
        "        # if((epoch_generator_loss - epoch_discriminator_loss)>3):\n",
        "        #     train_generator_num = 2\n",
        "        # else:\n",
        "        #     train_generator_num = 1\n",
        "\n",
        "        for _ in range(train_generator_num):\n",
        "            input_tensors = input_creator(labels)\n",
        "            images_generated = generator(input_tensors)\n",
        "            output = discriminator(images_generated)\n",
        "            label = find_label(labels)\n",
        "            loss_generator = criterion(output, label)\n",
        "\n",
        "            # input_tensors = input_tensors + small_noise_for_latent_space(input_tensors)\n",
        "            # images_generated_zcr = generator(input_tensors)\n",
        "            # loss_generator_auxiliary = -auxiliary_criterion(images_generated_zcr, images_generated)\n",
        "\n",
        "            loss_mse = auxiliary_criterion(images_generated, images)\n",
        "\n",
        "            optimizer_G.zero_grad()\n",
        "            loss_generator_final = loss_generator + loss_mse #+ 0.5 * loss_generator_auxiliary\n",
        "            if(labels.numel() != batch_size):\n",
        "                epoch_generator_loss = loss_generator.item()\n",
        "                print(\"Generator loss\", loss_generator.item())\n",
        "            loss_generator_final.backward()\n",
        "            optimizer_G.step()\n",
        "\n",
        "    # scheduler_generator.step()\n",
        "    # scheduler_discriminator.step()\n",
        "\n",
        "    input_tensors = input_creator(labels)\n",
        "    images_generated = generator(input_tensors)\n",
        "    images_generated = images_generated.to(\"cpu\").detach()\n",
        "\n",
        "    for i in range(10):\n",
        "        plt.imshow(images_generated[i][0])\n",
        "        plt.show()\n",
        "\n",
        "print(\"Done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1H8tOBTakfQB",
      "metadata": {
        "id": "1H8tOBTakfQB"
      },
      "outputs": [],
      "source": [
        "# This saves the models\n",
        "torch.save(generator, \"generator\")\n",
        "torch.save(discriminator, \"discriminator\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZH-OoxGtkjuw",
      "metadata": {
        "id": "ZH-OoxGtkjuw"
      },
      "outputs": [],
      "source": [
        "# Create the labels for visualization\n",
        "labels = torch.tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
        "input_tensor = input_tensors = input_creator(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "duna4WGMk1dY",
      "metadata": {
        "id": "duna4WGMk1dY"
      },
      "outputs": [],
      "source": [
        "# Use matplotlib to visualize\n",
        "images_generated = generator(input_tensor)\n",
        "for i in range(10):\n",
        "    plt.imshow(images_generated[i][0].to(\"cpu\").detach())\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
