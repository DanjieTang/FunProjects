{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.functional as F\n",
        "import pandas as pd\n",
        "import torch.optim as opt\n",
        "import numpy\n",
        "from torchtext.vocab import GloVe\n",
        "import random\n",
        "\n",
        "torch.manual_seed(1)\n",
        "random.seed(1)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "gJpyKwfz_XeQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class onePercent():\n",
        "    def within_one_percent(self, num1, num2):\n",
        "        one_percent = abs(num1) * 0.01  # one percent of the first number\n",
        "        return abs(num1 - num2) <= one_percent"
      ],
      "metadata": {
        "id": "cTEAdoqc_bBG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class toGlove():\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def toGloVe(self, batch_sentence):\n",
        "        \"\"\"\n",
        "            Convert the tweets into GloVe embedding\n",
        "            pre - batch of sentences\n",
        "            post - a tensor representing the sentence, can directly input to \n",
        "                  rnn, with batch_first=False\n",
        "        \"\"\"\n",
        "\n",
        "        batch_embedding=[]\n",
        "\n",
        "        for sentence in batch_sentence:\n",
        "            old_sentence=sentence\n",
        "            sentence=sentence.replace(\",\", \"\")\n",
        "            sentence=sentence.replace(\"-\", \" \")\n",
        "            sentence=sentence.replace(\"--\", \" \")\n",
        "            sentence=sentence.replace(\":\", \"\")\n",
        "            sentence=sentence.replace(\";\", \"\")\n",
        "            sentence=sentence.replace(\"!\", \".\")\n",
        "            sentence=sentence.replace(\"?\", \".\")\n",
        "            sentence=sentence.replace(\"\\n\", \" \")\n",
        "            sentence=sentence.replace(\"(\", \" \")\n",
        "            sentence=sentence.replace(\")\", \" \")\n",
        "            sentence=sentence.replace(\"  \", \" \")\n",
        "            sentence=sentence.lower()\n",
        "\n",
        "            list_of_embedding=[]\n",
        "            sentence=sentence.split()\n",
        "\n",
        "            if(len(sentence)>10):\n",
        "                for i in range(10):\n",
        "                    list_of_embedding.append(glove[sentence[i]])\n",
        "            else:\n",
        "                for word in sentence:\n",
        "                    list_of_embedding.append(glove[word])\n",
        "            \n",
        "            list_of_embedding=torch.stack(list_of_embedding)\n",
        "\n",
        "            batch_embedding.append(list_of_embedding)\n",
        "\n",
        "        batch_embedding = nn.utils.rnn.pad_sequence(batch_embedding)\n",
        "\n",
        "        return batch_embedding"
      ],
      "metadata": {
        "id": "y66hU6TH_c8f"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.feature_extractor=nn.GRU(50, 10, 1)\n",
        "        self.classifier1=nn.Linear(10, 2)\n",
        "        self.classifier2=nn.Linear(2, 1)\n",
        "        self.sigmoid=nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, batch_embedding):\n",
        "        #RNN\n",
        "        output, _=self.feature_extractor(batch_embedding)\n",
        "        #Get the output embedding\n",
        "        output=output[-1,:]\n",
        "\n",
        "        #Input into the classifier\n",
        "        output=self.classifier1(output)\n",
        "        output=self.sigmoid(output)\n",
        "        output=self.classifier2(output)\n",
        "        output=self.sigmoid(output)\n",
        "        return output"
      ],
      "metadata": {
        "id": "Fv30kQPP_gVr"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_rnn=RNN()\n",
        "my_rnn= torch.load(\"Trump_Tweet.pth\", map_location=torch.device(device))\n",
        "my_rnn=my_rnn.to(device)"
      ],
      "metadata": {
        "id": "t2hASw2z_O2a"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Final testing stage\n",
        "glove = GloVe(name='6B', dim=50)\n",
        "to_glove=toGlove()\n",
        "my_tweet=[\"I am going to go fishing today\"]\n",
        "my_tweet=to_glove.toGloVe(my_tweet)\n",
        "my_tweet=my_tweet.to(device)\n",
        "trump_tweet=[\"I’ve done more in less than 4 years than Biden’s done in more than 40 years, including for Black America. Biden has been a part of every failed decision for decades. Bad Trade Deals, Endless Wars, you name it, he has shown a complete lack of leadership. He’s weak & shot!!!\"]\n",
        "trump_tweet=to_glove.toGloVe(trump_tweet)\n",
        "trump_tweet=trump_tweet.to(device)\n",
        "\n",
        "print(\"This is my tweet, the chance of this being a real Trump tweet is: \", my_rnn(my_tweet).item()*100, \"%\")\n",
        "print(\"This is Trump tweet, the chance of this being a real Trump tweet is: \", my_rnn(trump_tweet).item()*100, \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvGD_XbJsh3z",
        "outputId": "22187644-9ccc-4731-df50-02ae257f7844"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is my tweet, the chance of this being a real Trump tweet is:  8.218467980623245 %\n",
            "This is Trump tweet, the chance of this being a real Trump tweet is:  91.62430167198181 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "AnJULKgfrSpi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f565756a-40e5-4e94-a0ee-f2d5bd01ea31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Real Trump Loss 0.23312360048294067\n",
            "Generated Loss 0.18683865666389465\n",
            "0.0832766592502594 0.08311685174703598\n"
          ]
        }
      ],
      "source": [
        "#This is training the model\n",
        "df=pd.read_csv(\"realdonaldtrump.csv\")\n",
        "\n",
        "my_rnn=RNN()\n",
        "one_percent=onePercent()\n",
        "my_rnn=my_rnn.to(device)\n",
        "\n",
        "big_list=[]\n",
        "\n",
        "criterion=nn.BCELoss()\n",
        "optimizer=opt.Adam(my_rnn.parameters(), lr=0.001, weight_decay=0.00001)\n",
        "\n",
        "read=pd.read_csv(\"personality.csv\")\n",
        "\n",
        "my_batch=[0, 0, 0, 0, 0, 0, 0, 0]\n",
        "\n",
        "trump_loss=0\n",
        "generated_loss=0\n",
        "\n",
        "#Training the network\n",
        "size=len(df[\"content\"])\n",
        "random_size=len(read[\"Persona\"])-1\n",
        "epoch=1\n",
        "\n",
        "counter=0\n",
        "\n",
        "for j in range(epoch):\n",
        "    for i in range(size):\n",
        "        if(i%8==0 and i!=0):\n",
        "            #Switch 8 sentences of Trump tweet into embedding\n",
        "            my_batch_glove=to_glove.toGloVe(my_batch)\n",
        "            my_batch_glove=my_batch_glove.to(device)\n",
        "\n",
        "            #Get the output of the tweet\n",
        "            output=my_rnn(my_batch_glove)\n",
        "\n",
        "            #Get the correct answer tensor\n",
        "            correct_answer=torch.ones(8, 1)\n",
        "            correct_answer=correct_answer.to(device)\n",
        "\n",
        "            #Gradient descent\n",
        "            loss=criterion(output, correct_answer)\n",
        "            loss.backward()\n",
        "            trump_loss=loss.item()\n",
        "\n",
        "            if(i%10240==0):\n",
        "                print(\"Real Trump Loss\", loss.item())\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(my_rnn.parameters(), max_norm=1)\n",
        "\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            #Create a list with 8 elements, each of which is a sentence\n",
        "            list_of_random_sentences=[]\n",
        "            k=0\n",
        "            while(k<8):\n",
        "                #Get a random index of our sentence\n",
        "                random_index=random.randint(0, random_size)\n",
        "\n",
        "                sentence=read[\"Persona\"][random_index]\n",
        "                list_of_random_sentences.append(sentence)\n",
        "                k+=1\n",
        "\n",
        "            #Change the list of sentences into tensor embedding\n",
        "            list_of_random_sentences=to_glove.toGloVe(list_of_random_sentences)\n",
        "            list_of_random_sentences=list_of_random_sentences.to(device)\n",
        "\n",
        "            #Get the model predicted output\n",
        "            output=my_rnn(list_of_random_sentences)\n",
        "\n",
        "            #This sentence is a fake Trump tweet\n",
        "            correct_answer=torch.zeros(8, 1)\n",
        "            correct_answer=correct_answer.to(device)\n",
        "\n",
        "            #Gradient descent\n",
        "            loss=criterion(output, correct_answer)\n",
        "            if(i%10240==0):\n",
        "                print(\"Generated Loss\", loss.item())\n",
        "            loss.backward()\n",
        "\n",
        "            generated_loss=loss.item()\n",
        "            torch.nn.utils.clip_grad_norm_(my_rnn.parameters(), max_norm=1)\n",
        "\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if(generated_loss<0.1 and trump_loss<0.1):\n",
        "                counter+=1\n",
        "                if(counter>6):\n",
        "                    if(one_percent.within_one_percent(generated_loss, trump_loss)):\n",
        "                        print(generated_loss, trump_loss)\n",
        "                        break;\n",
        "            else:\n",
        "                counter=0\n",
        "        else:\n",
        "            my_batch[i%8]=df[\"content\"][i]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(my_rnn, 'Trump_Tweet.pth')"
      ],
      "metadata": {
        "id": "LdejRERxQsaA"
      },
      "execution_count": 39,
      "outputs": []
    }
  ]
}